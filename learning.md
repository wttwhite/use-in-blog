# 函数
- result.get_shape()
  - 获取结果张量的维度信息

# 基本概念
## 计算模型(计算图)
// 还没看懂

## 数据模型(张量)
所有数据都是通过张量的形式来表示, 在张量中并没有真正保存数字, 它保存的是如何得到这些数字的计算过程
### 对中间结果的引用
```
# a和b 就是对常量生成这个运算结果的引用
a = tf.constant([1.0, 2.0], name ="a")
b = tf.constant([2.0, 3.0], name ="b")
result = a + b

# Tensor("add:0", shape=(2,), dtype=float32)
```
### 获得计算结果
当计算图构造完成之后, 张量可以用来获得计算结果, 也就是得到真实的数字
```
print(tf.Session().run(result))
# [3. 5.]
```
### 变量
- 变量与张量的关系
  - 在tf中, 变量的声明函数tf.Variable是一个运算, 这个运算的结果就是一个张量
  - 变量是特殊的张量
- 所有变量都会被自动加入到GraphKeys.VARIABLES集合
- 如果声明函数时参数trainable为True, 那么这个变量将会被加入GraphKeys.TRAINABLE_VARIABLES
- tf中提供的神经网络优化算法会将GraphKeys.TRAINABLE_VARIABLES集合中的变量作为默认的优化对象
- 类型
  - 一个变量在构建之后, 它的类型就不能再改变
- 维度(shape)
  - 维度在程序运行中是有可能改变的, 但是需要通过设置参数validate_shape = False
  - 虽然tf支持更改维度, 但是实际中很少用
## 运行模型(会话)
- 会话拥有并管理tf程序运行时的所有资源
- 当所有计算完成之后,需要关闭会话来帮助系统回收资源, 否则就可能出现资源泄露的问题
### 第一种模式
明确调用会话生成函数和关闭会话函数
```
# 创建一个会话
sess = tf.Session()
# 得到运算结果
sess.run(result)
# 关闭会话使得本次运行中的资源可以被释放
sess.close()
```
# 实现神经网络
通过对参数的合理设置来解决分类或者回归问题
- 特征向量
  - 所有用于描述实体的数字的组合就是一个实体的特征向量, 通过特征提取, 就可以将实际问题中的实体转化为空间中的点
- 神经网络结构
  - 不同的神经元之间的连接结构
- 神经网络的优化过程
  - 优化神经元中参数的取值过程
- 全连接神经网络
  - 相邻两层之间任意两个节点之间都有连接
- 每个神经元的输入既可以是其他神经元的输出, 也可以是整个神经网络的输入
- 一个最简单的神经元结构的输出就是所有输入的加权和, 不同输入的权重就是神经元的参数


## 神经网络解决分类问题
- 提取问题中实体的特征向量作为输入
- 定义神经网络的结构, 并定义如何从神经网络的输入得到输出(前向传播算法)
- 通过训练数据集来调整神经网络中参数的取值(训练)
- 使用训练好的神经网络来预测未知的数据
### 前向传播算法
- 计算神经网络的前向传播结果需要三部分信息
  - 神经网络的输入, 就是从实体中提取的特征向量
  - 神经网络的连接结构
    - 神经网络是由神经元构成的, 神经网络的结构给出不同神经元(节点)之间输入输出的连接关系
  - 每个神经元中的参数
### 监督学习方式
  使用监督学习的方式来更合理地设置参数取值, 设置神经网络参数的过程就是神经网络的训练过程, 只有经过有效训练的神经网络模型才可以真正的解决分类或者回归问题

  > 使用监督学习的方式设置神经网络参数需要一个标注好的训练数据集 (eg. 收集的一批合格和不合格的零件)

  **重要思想: 在已知答案的标注数据集上, 模型给出的预测结果要尽量接近真实答案**

  通过调整神经网络中的参数对训练数据进行拟合, 可以使得模型对未知的样本提供预测的能力

## 训练神经网络过程
  - 定义神经网络的结构和前向传播的输出结果
  - 定义损失函数以及选择反向传播优化的算法
  - 生成会话并在训练数据上反复运行反向传播优化算法
  
# 函数方法

函数名 | 功能 | 使用
------- | ------- |  -------
all_variables | 获取当前计算图上所有的变量, 有助于持久化整个计算图的运行状态 | tf.all_variables()
trainable_variables | 得到所有需要优化的参数
initialize_all_variables | 初始化所有变量 | tf.initialize_all_variables()
